{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMEANS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMEANS\n",
    "\n",
    "El clustering con K-Means es bastante distinto al clustering jerarquico debido a que el número de clusters \"k\" necesita ser conocido a priorí antes de aplicar el modelo. Los datos se deviden en K-Grupos.\n",
    "\n",
    "El centroide de los cluster se seguira actualizando basandose en las observaciones de los nuevos clusters generados en cada etapa del algoritmo, y al final la salida será un arreglo conteniendo el id del cluster de las observaciones.\n",
    "\n",
    "El algoritmo es sencillo:\n",
    "\n",
    "- Se escoge el número k (número de centroides) y se ponen en un grafico de manera aleatoria.\n",
    "- El algoritmo converge cuando los datos estan agrupados en dos grupos.\n",
    "\n",
    "$$\n",
    "SS_w(C_j) = \\sum\\limits_{x \\in C_j}{(x - c_j)^2}\n",
    "$$\n",
    "\n",
    "Tambien podemos usar la distancia intracluster:\n",
    "$$\n",
    "SS'_w = \\sum\\limits_{j=1}^{k}{\\frac{SS_w(C_j)}{SS_T}}\n",
    "$$\n",
    "\n",
    "Donde\n",
    "\n",
    "$$\n",
    "SS_T = \\sum\\limits_{i=1}^{n}{(x_i - \\overline{x})^2}\n",
    "$$\n",
    "\n",
    "Todo esto con el fin de recalcular la posición de los varicentros o centroides.\n",
    "\n",
    "- Repetimos hasta que ni una de las observaciones sea reasignada a un cluster distinto al que pertenece, y damos por finalizado el algoritmo de K-means y se dice que se llega a una solución correcta debido a que no se puede ajustar mejor. \n",
    "\n",
    "La formula en el caso de un cluster, siempre es 1. Y mientras mas clusters haya, mas pequeño es el número, por lo tanto el objetivo es minimizar tanto como se pueda esta metrica, para alcanzar la convergencia. Siempre se tiene en cuenta que el numero final de clusters es \"k\", que es el parámetro que nosotros proveemos al modelo.\n",
    "\n",
    "El objetivo es encontrar los varicerntros que sean capaces de minimizar la suma total de cada uno de los cuadrados internos para cada cluster.\n",
    "\n",
    "Entonces se tienen que buscar los $C_j$ para la siguiente formula:\n",
    "$$\n",
    "SS_w(k) = \\sum\\limits^k_{j=1}{SS_w(C_j)} = \\sum\\limits^k_{j=1}\\sum\\limits_{x_i \\in C_j}{(x_i - c_j)^2}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- k: Es el número de clusters.\n",
    "- $x_i$: Los puntos que pertenecen al j-esimo cluster.\n",
    "- $c_j$: El centroide del cluster j-esimo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "        1, 0, 1, 0, 0, 0, 0, 1]),\n",
       " array([0.58424996, 0.24185582, 0.34585569, 0.82055806, 0.        ,\n",
       "        0.67754617, 0.59291315, 0.63523767, 0.44353201, 0.51384831,\n",
       "        0.25683366, 0.98671279, 0.73767587, 0.51013258, 0.        ,\n",
       "        0.3913516 , 0.83842929, 0.97681581, 0.58881286, 0.67349922,\n",
       "        0.7867056 , 0.60101049, 0.2382556 , 0.58106169, 0.45871135,\n",
       "        0.57854958, 0.83552434, 0.26792655, 0.76466917, 0.64019997]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implementación de KMEANS\n",
    "import numpy as np\n",
    "from scipy.cluster.vq import vq\n",
    "np.random.seed(42)\n",
    "\n",
    "X = np.random.random((90)).reshape(30, 3)\n",
    "\n",
    "# Para definir los centroides iniciales, tomamos 3 puntos aleatorios\n",
    "c1 = np.random.choice((range(len(X)))) # 1er centroide\n",
    "c2 = np.random.choice((range(len(X)))) # 2do centroide\n",
    "\n",
    "# Ahora los asignamos aleatoriamente\n",
    "clust_center = np.vstack((X[c1], X[c2]))\n",
    "\n",
    "# Implementación de KMEANS\n",
    "vq(X, clust_center)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.4523365 , 0.20781291, 0.52340274],\n",
       "        [0.48147176, 0.8445533 , 0.39662412]]),\n",
       " 0.37920139550151216)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.cluster.vq import kmeans\n",
    "kmeans(X, clust_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.48147176, 0.8445533 , 0.39662412],\n",
       "        [0.4523365 , 0.20781291, 0.52340274]]),\n",
       " 0.37920139550151216)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans(X, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
